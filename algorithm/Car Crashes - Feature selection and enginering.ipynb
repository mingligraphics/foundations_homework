{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection and feature engineering\n",
    "\n",
    "This isn't based on a news article, exactly, it's from a paper. You can see the paper in `/data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in our data\n",
    "\n",
    "## Every single person in a crash\n",
    "\n",
    "We'll start by reading in the list of people who were involved in an accident.\n",
    "\n",
    "**Call this dataframe `people`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often did each severity of injury show up? (e.g. not injured, non-incapacitating injury, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're only interested in fatalities, so let's create a new `had_fatality` column for when people received a fatal injury.\n",
    "\n",
    "**Confirm there were 1681 people with fatal injuries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on Features\n",
    "\n",
    "### Starting our analysis\n",
    "\n",
    "We're going to run a regression on the impact of being **male vs female on crash fatalities**. Prepare a dataframe called `train_df` with the appropriate information in it.\n",
    "\n",
    "* **Tip:** What column(s) are your input, and what is your output? Aka independent and dependent variables\n",
    "* **Tip:** You'll need to convert your input column into something numeric, I suggest using `.replace`\n",
    "* **Tip:** We aren't interested in the \"Unknown\" sex - either filtering or `np.nan` + `.dropna()` might be useful ways to get rid of those columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that your `train_df` has two columns and 815,827 rows.\n",
    "\n",
    "> **Tip:** If you have more rows, make sure you dropped all of the rows with Unknown sex.\n",
    ">\n",
    "> **Tip:** If you have more columns, make sure you only have your input and output columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your regression\n",
    "\n",
    "See the effect of sex on whether the person's injuries are fatal or not. After we train the regression, we can use my ✨favorite technique✨ to display features and their odds ratios:\n",
    "    \n",
    "```python\n",
    "feature_names = X.columns\n",
    "coefficients = clf.coef_[0]\n",
    "\n",
    "pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient (log odds ratio)': coefficients,\n",
    "    'odds ratio': np.exp(coefficients).round(4)\n",
    "}).sort_values(by='odds ratio', ascending=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use words to interpret this result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more features\n",
    "\n",
    "The actual crash data has more details - whether it was snowy/icy, whether it was a highway, etc. \n",
    "\n",
    "Read in `combined-crash-data.csv`, calling it **`crashes`**, and merge it with our people dataset. I'll save you a lookup: the `REPORT_NO` is what matches between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining more possible features\n",
    "\n",
    "How often was it wet, dry, snowy, icy, etc? **What was the most common surfce condition?**\n",
    "\n",
    "* **Tip:** We're interested in surface condition, _not_ road condition, _not_ weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you feel that a **Dry** road condition should be the average of **Wet** and **Snow?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer to that should be *no*, which means we can't use this data as numeric data. We want a different coefficient for each of these - I want to know the impact of dry, the impact of wet, the impact of snow, all separately.\n",
    "\n",
    "Start by **replacing each code with a proper description.** I'll even include them here:\n",
    "\n",
    "* `00` - Not Applicable\n",
    "* `01`\t- Wet\n",
    "* `02`\t- Dry\n",
    "* `03`\t- Snow\n",
    "* `04`\t- Ice\n",
    "* `05`\t- Mud, Dirt, Gravel\n",
    "* `06`\t- Slush\n",
    "* `07`\t- Water (standing/moving)\n",
    "* `08`\t- Sand\n",
    "* `09`\t- Oil\n",
    "* `88`\t- Other\n",
    "* `99`\t- Unknown\n",
    "\n",
    "But watch out, pandas read the column in as numbers so they might have come through a little differently than their codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm you have 147,803 wet, and a few codes you can't understand, like `6.03` and `7.01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the codes you don't understand with `Other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm you have 3,196 'Other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "\n",
    "We're going to use `pd.get_dummies` to build a variable you'll call `surf_dummies`. Each surface condition should be a `0` or `1` as to whether it was that condition (dry, icy, wet, etc).\n",
    "\n",
    "Use a `prefix=` so we know they are **surface** conditions.\n",
    "\n",
    "You'll want to drop the column you'll use as the reference category.\n",
    "\n",
    "**Before we do this: which column works best as the reference?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build your `surf_dummies` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm your `surf_dummies` looks roughly like this:\n",
    "\n",
    "|surface_Ice|Surce_Mud, Dirt, Gravel|surface_Not Applicable|...|surface_Wet|\n",
    "|---|---|---|---|---|\n",
    "|0|0|0|...|0|\n",
    "|0|0|0|...|0|\n",
    "|0|0|1|...|0|\n",
    "|0|0|1|...|0|\n",
    "|0|0|0|...|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another regression\n",
    "\n",
    "Let's run another regression to see the impact of both **sex and surface condition** on fatalities.\n",
    "\n",
    "### Build your `train_df`\n",
    "\n",
    "To build your `train_df`, I recommend doing it either of these two ways. They both first select the important columns, then add in the one-hot encoded `surf_dummies` columns.\n",
    "\n",
    "```python\n",
    "train_df = pd.DataFrame({\n",
    "    'col1': merged.col1,\n",
    "    'col2': merged.col2,\n",
    "    'col3': merged.col3,\n",
    "})\n",
    "train_df = train_df.join(surf_dummies)\n",
    "train_df = train_df.dropna()\n",
    "train_df.head()\n",
    "```\n",
    "\n",
    "or like this:\n",
    "\n",
    "```python\n",
    "train_df = train_df[['col1','col2','col3']].copy()\n",
    "train_df = train_df.join(surf_dummies)\n",
    "train_df = train_df.dropna()\n",
    "train_df.head()\n",
    "```\n",
    "\n",
    "The second one is shorter, but the first one makes it easier to use comments to remove columns later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your regression and check your odds ratios\n",
    "\n",
    "Actually no, wait, first - what kind of surface do you think will have the **highest fatality rate?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm your `train_df` has 815,843 rows and 9 columns.\n",
    "\n",
    "* **Tip:** When you run your regression, if you get an error about not knowing what to do with `U`, it's because you didn't convert your sex to numbers (or if you did, you didn't do it in your original dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is this what you expected?** Why do you think this result might be the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More features: Vehicles\n",
    "\n",
    "Maybe the car they're in is related to the car they were in. Luckily, we have this information - **read in `combined_vehicle_data` as `vehicles`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights of those cars\n",
    "\n",
    "The car weights are stored in **another file** since the info had to come from an API. I looked up the VINs - vehicle identification numbers - in a government database to try to get data for each of them.\n",
    "\n",
    "**Read them and build a new dataframe that is both the vehicle data along with their weights.** You can call it `vehicles` since you don't need the original weightless vehicle data any more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that your combined `vehicles` dataset should have 534,436 rows and 35 columns. And yes, that's less than we were working with before - you haven't combined it with the people/crashes dataset yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter your data\n",
    "\n",
    "We only want vehicles that are \"normal\" - somewhere between 1500 and 6000 pounds. Filter your vehicles to only include those in that weight range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that you have 532,370 vehicles in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add this vehicle information to your merged data\n",
    "\n",
    "Now we'll have a dataframe that contains information on:\n",
    "\n",
    "* The people themselves and their injuries\n",
    "* The crash\n",
    "* The vehicles\n",
    "\n",
    "Every person came with a `VEHICLE_ID` column that is the vehicle they were in. You'll want to merge on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm you have 99 columns and 616,212 rows. **That is a lot of possible features!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another regression, because we can't get enough\n",
    "\n",
    "Build another `train_df` and run another regression about **how car weight impacts the chance of fatalities**. You'll want to confirm that your dataset has 616,212 and 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can you translate that into plain English?** Remember weight is in **pounds**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I feel like pounds isn't the best measure for something like this. Remember how we had to adjust percentages with AP and life expecntancy, and then change around the way we said things? It sounded like this:\n",
    "\n",
    "> Every 10% increase in unemployment translates to a year and a half loss of life expectancy\n",
    "\n",
    "Instead of every single pound, maybe we could do every... some other number of pounds? One hundred? One thousand?\n",
    "\n",
    "**Run another regression with weight in thousands of pounds.** Get another odds ratio. Give me another sentence English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every thousand pounds heavier your car is increase translates to a 15% decrease in fatalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-car accidents, struck and striker\n",
    "\n",
    "Here's the thing, though: **it isn't just the weight of your car.** It's the weight of both cars! If I'm in a big car and I have a wreck with a smaller car, it's the smaller car that's in trouble.\n",
    "\n",
    "To get that value, we need to do some **feature engineering**, some calculating of *new* variables from our *existing* variables.\n",
    "\n",
    "We need to jump through some hoops to do that.\n",
    "\n",
    "##  Two-car accidents\n",
    "\n",
    "First we're going to count how many vehicles were in each accident. Since we're looking to compare the weight of two cars hitting each other, **we're only going to want crashes with only two cars.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted = vehicles.REPORT_NO.value_counts()\n",
    "counted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using `.value_counts` I can see how many cars were in each crash, and now I'm going to filter to get a list of all of the ones with two vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_car_report_nos = counted[counted == 2].index\n",
    "two_car_report_nos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll filter my vehicles so we only have those that were in two-vehicle crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = vehicles[vehicles.REPORT_NO.isin(two_car_report_nos)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Struck and striker\n",
    "\n",
    "To do the math correctly, we need both the risk of someone dying in the smaller car _and_ the risk of someone dying in the bigger car. To do this we need to separate our cars into two groups:\n",
    "\n",
    "* The 'struck' vehicle: did the person die inside?\n",
    "* The 'striker' vehicle: how much heavier was it than the struck car?\n",
    "\n",
    "But we don't know which car was which, so we have to try out both versions - pretending car A was the striker, then pretending car B was the striker. It's hard to explain, but you can read `Pounds That Kill - The External Costs of Vehicle Weight.pdf` for more details on how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_1 = vehicles.drop_duplicates(subset='REPORT_NO', keep='first')\n",
    "cars_2 = vehicles.drop_duplicates(subset='REPORT_NO', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_merged_1 = cars_1.merge(cars_2, on='REPORT_NO', suffixes=['_striker', '_struck'])\n",
    "cars_merged_2 = cars_2.merge(cars_1, on='REPORT_NO', suffixes=['_striker', '_struck'])\n",
    "vehicles_complete = pd.concat([cars_merged_1, cars_merged_2])\n",
    "vehicles_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put people in their cars\n",
    "\n",
    "Which car was each person in? We'll assign that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = people.merge(vehicles_complete, left_on='VEHICLE_ID', right_on='VEHICLE_ID_struck')\n",
    "merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the crash details\n",
    "\n",
    "You did this already! I'm going to do it for you. We're merging on `REPORT_NO_x` because there are so many `REPORT_NO` columns duplicated across our files that pandas started giving them weird names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(crashes, left_on='REPORT_NO_x', right_on='REPORT_NO')\n",
    "merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter\n",
    "\n",
    "We already filtered out vehicles by weight, so we don't have to do that again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculated features\n",
    "\n",
    "I'm sure you forgot what all the features are, so we'll bring back whether there was a fatality or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Accident was fatal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['had_fatality'] = (merged.INJ_SEVER_CODE == 5).astype(int)\n",
    "merged.had_fatality.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Weight difference\n",
    "\n",
    "**Remove everything missing weights for strikers or struck vehicles.** You might need to `merged.columns` to remind yourself what the column names are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm your dataset has roughly 335,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new feature called `weight_diff` about how much heavier the striking car was compared to the struck car. **Make sure you've done the math correctly!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature adjustment\n",
    "\n",
    "Make all of your weight columns in **thousands of pounds** instead of just in pounds. It'll help you interpret your results much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another regression!!!\n",
    "\n",
    "**What is the impact of weight difference on fatality rate?** Create your `train_df`, drop missing values, run your regression, analyze your odds ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please translate your odds ratio into plain English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding in more features\n",
    "\n",
    "How about speed limit? That's important, right? We can add the speed limit of the striking vehicle with `SPEED_LIMIT_striker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you translate the speed limit odds ratio into plain English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering: Speed limits\n",
    "\n",
    "Honestly, that's a pretty bad way to go about things. What's more fun is if we **translate speed limits into bins.**\n",
    "\n",
    "First, we'll use `pd.cut` to assign each speed limit a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_bins = [-np.inf, 10, 20, 30, 40, 50, np.inf]\n",
    "merged['speed_bin'] = pd.cut(merged.SPEED_LIMIT_struck, bins=speed_bins)\n",
    "merged[['SPEED_LIMIT_striker', 'speed_bin']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll one-hot encode around 20-30mph speed limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_dummies = pd.get_dummies(merged.speed_bin, \n",
    "                               prefix='speed').drop('speed_(20.0, 30.0]', axis=1)\n",
    "speed_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a regression\n",
    "\n",
    "I like this layout for creating `train_df`, it allows us to easily add dummies and do a little replacing/encoding when we're building binary features like for sex.\n",
    "\n",
    "> If the below gives you an error, it's because `SEX_CODE` is already a number. In that case, just remove `.replace({'M': 1, 'F': 0, 'U': np.nan })`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with our normal features\n",
    "train_df = pd.DataFrame({\n",
    "    'weight_diff': merged.weight_diff,\n",
    "    'sex': merged.SEX_CODE,#.replace({'M': 1, 'F': 0, 'U': np.nan }),\n",
    "    'had_fatality': merged.had_fatality,\n",
    "})\n",
    "# Add the one-hot encoded features\n",
    "train_df = train_df.join(speed_dummies)\n",
    "train_df = train_df.join(surf_dummies)\n",
    "# Drop missing values\n",
    "train_df = train_df.dropna()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the impact of the different variables in simple language. What has the largest impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now you pick the features\n",
    "\n",
    "Up above you have examples of:\n",
    "\n",
    "* Creating features from numbers (speed limits)\n",
    "* Creating features from 0/1 (sex)\n",
    "* Creating features from binning numbers that are one-hot encoded (speed limit bins - `speed_bins`)\n",
    "* Creating features from categories that are one-hot encoded (surface - `surf_dummies`\n",
    "\n",
    "What else do you think matters? Try to plug in more features and see if you can get anything interesting.\n",
    "\n",
    "> * **Hot tip:** The funniest/most interesting thing feature you can add is also the dumbest. Ask me about it in #algorithms if you end up getting down here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
